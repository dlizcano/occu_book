[["index.html", "Occupancy simulation and analysis Understanding the simulations and the basic occupancy model Chapter1 Prerequisites 1.1 Please cite this work as:", " Occupancy simulation and analysis Understanding the simulations and the basic occupancy model Diego J. Lizcano, Ph.D. 2022-06-26 Chapter1 Prerequisites This is a tutorial book written with Markdown Using R y R studio, using the bookdown, knitr and rmarkdown packages. This book-tutorial is part of the mini course on occupation methods with R. Before starting please install the JAGS program on your computer, then from R studio install the unmarked, raster, spatstat, jagsUI, mcmcplots and ggmcmc packages. install.packages(&quot;unmarked&quot;, dependencies = TRUE) install.packages(&quot;raster&quot;, &quot;spatstat&quot;, &quot;jagsUI&quot;, &quot;mcmcplots&quot;, &quot;ggmcmc&quot;, dependencies = TRUE) 1.1 Please cite this work as: Lizcano D.J. (2019). Simulación y análisis de ocupación. Entendiendo las simulaciones y el modelo básico de ocupación (Version 1). Zenodo. http://doi.org/10.5281/zenodo.4028019 This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International] license(https://creativecommons.org/licenses/by-sa/4.0/deed.en). "],["why.html", "Chapter2 Why to do simulations? 2.1 why simulations are useful:", " Chapter2 Why to do simulations? 2.1 why simulations are useful: When doing simulations, the true parameters are known, so we can ensure that the code we execute (R or BUGS) estimates what we want, and that the estimates are equal to or close to the true parameters, allowing us to debug errors in the code. We can calibrate a derived and/or more complex model more easily. Simulations can be viewed as a controlled experiment, or as simplified versions of a real system, in which we can test how certain parameters vary and affect estimates of other parameters. Conducting controlled experiments in the real world is often impractical or impossible in ecology, so simulation is the most consistent way to study the ecological system. Sampling error is experienced firsthand and becomes a fantastic learning process. We can check the quality (frequentist) of the estimates, as well as the precision and the effect of sample size, by computing the difference between the mean of the estimate and the true value (bias) and the variance of the estimates (the precision). It is the most flexible and direct way to carry out power analysis, solving the great problem of determining the sample size necessary to detect an effect of a certain magnitude, with a given probability. We can visualize how identifiable the parameters are in more complex models. We can check how robust the model is to violations of the assumptions. Being able to simulate data under a particular model ensures that one understands the model, its constraints, and limitations. "],["occu.html", "Chapter3 The Occupancy", " Chapter3 The Occupancy Obtaining data for studies of animal populations is costly and wasteful, and it is not always possible to measure population density or demographic parameters such as birth or mortality rates. That is why the estimation of habitat occupation (\\(\\psi\\)) is a good study tool since it is a reflection of other important population parameters such as abundance and density, which require a high number of records, with the economic and logistical costs involved. Additionally, and because detectability (p) in wild animals is not complete, the use of raw data generates underestimates of habitat occupation. Using repeated sampling, it is possible to generate estimates of detectability and, with this estimate, obtain unbiased values of habitat occupancy. Occupancy analysis methods were initially developed by (Darryl I. MacKenzie et al., 2002) and later expanded by other authors (M. Kéry &amp; Royle, 2008; Darryl I. MacKenzie et al., 2006; Darryl I. MacKenzie &amp; Royle, 2005; J. Andrew Royle, 2006; J. Andrew Royle &amp; Kéry, 2007; J. Andrew Royle, Nichols, K&amp;eacute, &amp; Ry, 2005). These types of models allow inferences to be made about the effects of continuous and categorical variables on habitat occupancy. Furthermore, if sampling is done over long periods, it is also possible to estimate extinction and recolonization rates, which are useful in metapopulation studies (Darryl I. MacKenzie, Nichols, Hines, Knutson, &amp; Franklin, 2003). This is a field of great development in biostatistics that has produced a great explosion of studies that use occupation taking detectability into account (Guillera-Arroita, 2011; Guillera-Arroita &amp; Lahoz-Monfort, 2012; Guillera-Arroita et al., 2015; Guillera-Arroita, Ridout, &amp; Morgan, 2010; Guillera-Arroita, Ridout, &amp; Morgan, 2014; Marc Kéry, Guillera-Arroita, &amp; Lahoz-Monfort, 2013). References Guillera-Arroita, G. (2011). Impact of sampling with replacement in occupancy studies with spatial replication. Methods in Ecology and Evolution, 2(4), 401406. doi: 10.1111/j.2041-210X.2011.00089.x Guillera-Arroita, G., &amp; Lahoz-Monfort, J. J. (2012). Designing studies to detect differences in species occupancy: power analysis under imperfect detection. Methods in Ecology and Evolution, 3(5), 860869. doi: 10.1111/j.2041-210X.2012.00225.x Guillera-Arroita, G., Lahoz-Monfort, J. J., Elith, J., Gordon, A., Kujala, H., Lentini, P. E.,  Wintle, B. A. (2015). Is my species distribution model fit for purpose? Matching data and models to applications. Global Ecology and Biogeography, 24(3), 276292. doi: 10.1111/geb.12268 Guillera-Arroita, G., Ridout, M. S., &amp; Morgan, B. J. T. (2010). Design of occupancy studies with imperfect detection. Methods in Ecology and Evolution, 1(2), 131139. doi: 10.1111/j.2041-210X.2010.00017.x Guillera-Arroita, G., Ridout, MartinS., &amp; Morgan, ByronJ. T. (2014). Two-Stage Bayesian Study Design for Species Occupancy Estimation. Journal of Agricultural, Biological, and Environmental Statistics, 114. doi: 10.1007/s13253-014-0171-4 Kéry, Marc, Guillera-Arroita, G., &amp; Lahoz-Monfort, J. J. (2013). Analysing and mapping species range dynamics using occupancy models. Journal of Biogeography, 40(8), 14631474. doi: 10.1111/jbi.12087 Kéry, M., &amp; Royle, J. A. (2008). Hierarchical Bayes estimation of species richness and occupancy in spatially replicated surveys. Journal of Applied Ecology, 45(2), 589598. doi: 10.1111/j.1365-2664.2007.01441.x MacKenzie, Darryl I., Nichols, J. D., Hines, J. E., Knutson, M. G., &amp; Franklin, A. B. (2003). Estimating site occupancy, colonization, and local extinction when a species is detected imperfectly. Ecology, 84(8), 22002207. doi: 10.1890/02-3090 MacKenzie, Darryl I., Nichols, J. D., Lachman, G. B., Droege, S., Andrew Royle, J., &amp; Langtimm, C. A. (2002). Estimating site occupancy rates when detection probabilities are less than one. Ecology, 83(8), 22482255. doi: 10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2 MacKenzie, Darryl I., Nichols, J., Royle, J. A., Pollock, K., Bailey, L., &amp; Hines, J. (2006). Occupancy estimation and modeling: inferring patterns and dynamics of species occurrence (p. 324). Burlington, MA: Academic Press. MacKenzie, Darryl I., &amp; Royle, J. A. (2005). Designing occupancy studies: general advice and allocating survey effort. Journal of Applied Ecology, 42(6), 11051114. doi: 10.1111/j.1365-2664.2005.01098.x Royle, J. Andrew. (2006). Site occupancy models with heterogeneous detection probabilities. Biometrics, 62(1), 97102. doi: 10.1111/j.1541-0420.2005.00439.x Royle, J. Andrew, &amp; Kéry, M. (2007). A Bayesian state-space formulation of dynamic occupancy models. Ecology, 88(7), 18131823. doi: 10.1890/06-0669.1 Royle, J. Andrew, Nichols, J. D., K&amp;eacute, &amp; Ry, M. (2005). Modelling occurrence and abundance of species when detection is imperfect. Oikos, 110, 353359. doi: 10.1111/j.0030-1299.2005.13534.x "],["example.html", "Chapter4 Our Example: 4.1 Initial steps: sample size and covariate values 4.2 Simulating the ecological process and its result: the occurrence of The Tapir 4.3 Simulating the observation process and its result: the detection", " Chapter4 Our Example: The data set that we are going to simulate mimics the spatial and temporal way in which we imagine the repeated measures of presence-absence in ecology originate. Which are a combination of an ecological process and an observation process. The first process contains the mechanisms under which Spatio-temporal distribution patterns originate, while the second process contains the different facets in which sources of error originate when taking the data. To be more concrete we are going to call our imaginary species by a real name. We will call it the Mountain Tapir (Tapirus pinchaque), a large and conspicuous mammal, distributed from Colombia to Ecuador and Northern Peru, and listed as endangered in terms of conservation. Mountain tapir in Los Nevados National Park. Colombia Though it is the smallest (and furriest!) of tapir species, the Mountain tapir is the largest mammal in the tropical Andes mountain range. Their long hair is brownish to black, and their lips are lined in a white color. The data set contains J replicated data of detection or non-detection of the species in M sites, taking into account that we assume that it is a closed population (closure assumption). This means that during the sampling there were no changes due to births, deaths, immigration or emigration. In other words, the sampling was short in time and the occurrence of species z did not change due to demographic effects. Clearly, we must distinguish two processes, the first is the ecological process, which generates (partially) a latent state of the occurrence z. The second is the observation process, which produces the observed tapir detection or non-detection data. Here we assume that the observation process is governed by an imperfect detection mechanism. In other words, some tapir could have escaped my observation, which generates false negatives. We also assume that false positives are absent, meaning that anything I identify as a tapir is indeed a tapir and not a deer or a bear. To make the example more realistic, we include the effects of elevation (altitude) and forest cover on occurrence, as factors that affect occurrence linearly, decreasing it in the case of elevation, and increasing occupation linearly in the case of forest cover. In the end the two variables interact negatively with each other. These effects are introduced in the logarithmic scale occurrence as a generalized linear model (GLM) is traditionally done. In our simulation we are going to make it explicit that it is not possible to detect all the tapirs from a sample site, so we are facing a type of error that makes us underestimate the abundance of the population. There are many reasons why we fail to spot an individual in the wild, it can be because we got distracted while the tapir passed by, because the binoculars did not have enough magnification, or simply because the tapir hid behind a tree upon smelling us, or because some other reason. In this way, we are going to register the presence (z=1) with a probability of detection p which we are also going to make dependent (on the logarithmic scale) of the elevation and of a co-variable that affects the detection, the temperature. In general terms, animals are more difficult to observe when the temperature is higher, and generally the higher the elevation, the lower the temperature. In this way, we assume that detection is negatively related to elevation and temperature. But it should also be noted that the negative effect on p can also be mediated by a decrease in abundance with elevation, which also causes the probability of occupancy to decrease with elevation. Note that a co-variable, elevation affects both the ecological process (the occurrence) and the observational process (the probability of detection). This has a purpose and is likely to happen in nature many times. Occupancy models have a mechanistic basis producing a spatial variation in abundance. That is, we will have sites with greater abundance and others with less abundance. But hierarchical models, like the one we are about to build, are capable of unraveling these complex relationships between occurrence and probability of detection (M. Kéry, 2008; M. Kéry &amp; Royle, 2008; Marc Kéry &amp; Schaub, 2012). Finally, for this first example, we are going to leave out the effect of the interaction between elevation and temperature, setting it to zero. Then we can vary this parameter to consider that effect. In summary, we are going to generate data under the following model, where the sites are indexed as i and the repeated counts on the site are going to be referred to as j. 4.0.1 Ecological Model: \\[\\begin{equation} z _{i} = Bernoulli (\\psi _{i}) \\tag{4.1} \\end{equation}\\] \\[\\begin{equation} logit(\\psi _{i}) = \\beta _{0} + \\beta _{1} \\ast Elevation _{i} + \\beta _{2}\\ast CovForest _{i} + \\beta _{3} \\ast Elevation _{i} \\ast CovForest _{i} \\tag{4.1} \\end{equation}\\] 4.0.2 Observation Model: \\[\\begin{equation} y _{ij} = Bernoulli (z _{i} * p _{ij}) \\tag{4.1} \\end{equation}\\] \\[\\begin{equation} logit(p _{ij}) = \\alpha _{0} + \\alpha _{1} \\ast Elevation _{i} + \\alpha _{2}\\ast Temperature _{ij} + \\alpha _{3} \\ast Elevation _{i} \\ast Temperature _{ij} \\tag{4.1} \\end{equation}\\] Where \\(\\psi\\) is the occupancy and p the probability of detection. With \\(\\beta\\) as the regression coefficient for the occupancy covariates and \\(\\alpha\\) the regression coefficient for the detection covariates. We are going to generate data from the inside out and from the top down. For this, we first choose the sample size and create the values for the covariates. Second, we select the values of the ecological model parameters (the occupancy) and assemble the expected occurrence (the parameter \\(\\psi\\), occupancy) and then obtain the random variable z which has a Bernoulli distribution. Third, we select the values of the parameters of the observation model (the detection), to assemble the probability of detection p and obtain the second set of a random variable y (observed or unobserved detection of a tapir) which also has distribution Bernoulli. To simulate the data we will use the statistical programming language R (R Core Team, 2016), which provides a wide variety of graphical and statistical modeling techniques and a large ecosystem of packages for statistical and ecological analysis. If you havent already, download and install R on your computer, then do the same with RStudio. 4.1 Initial steps: sample size and covariate values Start RStudio, copy, paste and execute the commands in the gray window. We first choose the sample size, the number of sites, and the number of repeated measures (number of visits) of presence/absence at each site. M &lt;- 60 # Number of spatial replicas (sites) J &lt;- 30 # Number of temporal replicas (repeat counts) We then create the values for the covariates. We have elevation and forest cover as co-variables for each site. They differ from site to site but for each sampling, they are the same. While the temperature is a co-variable of the observation, so it does vary in each sampling and also in each site. Remember that the sub-index i refers to the site and the j to each sampling. To keep things simple our covariates are going to have a normal distribution with a mean-centered at zero and not going to extend very far on either side of zero. In real data analysis, we will have to standardize the co-variables to avoid numerical problems of difference in the scales of the co-variables and to be able to calculate the value of maximum likelihood (ML), as well as to obtain convergence in the Markov chains of the Bayesian model. Here we are going to ignore a fact of real life, and that is that the co-variables are not totally independent of each other, that is, in nature, forest cover can be related to elevation, but this is not going to be relevant, for now. To initialize the random number generator and always get the same results we can add the following line: set.seed(24) # Can choose seed of your choice In this way, we can always obtain the same estimates. But then when we want to get the sampling error we will have to remove that line. For this example, we will generate values already standardized for the covariates, which are centered at zero and ranging from -1 to 1. elev &lt;- runif(n = M, -1, 1) # Scaled elevation of a site forest &lt;- runif(n = M, -1, 1) # Scaled forest cover at each site temp &lt;- array(runif(n = M*J, -1, 1), dim = c(M, J)) # Scaled temperature 4.2 Simulating the ecological process and its result: the occurrence of The Tapir To simulate the occurrence of tapirs at each site, we choose the values for the parameters that govern the spatial variation in occurrence \\(_{0}\\) to \\(_{3}\\). The first parameter is the expected average occurrence of tapir (occupation probability) when all covariates have a value of zero, in other words the intercept of the occurrence model. We prefer to think of tapir in terms of their occurrence rather than logit (occurrence). Here we choose the occupancy intercept first and then transform it from the logarithmic scale with the logit link function. mean.occupancy &lt;- 0.60 # Mean expected occurrence of tapir beta0 &lt;- plogis(mean.occupancy) # Same on logit scale (= logit-scale intercept) beta1 &lt;- -2 # Effect (slope) of elevation beta2 &lt;- 2 # Effect (slope) of forest cover beta3 &lt;- 1 # Interaction effect (slope) of elev and forest Here we apply the linear model (to the logarithmic scale) and obtain the logit transformation of the occupancy probability, which we invert with the logit transformation to obtain the tapir occupancy and plot everything. logit.psi &lt;- beta0 + beta1 * elev + beta2 * forest + beta3 * elev * forest psi &lt;- plogis(logit.psi) # Inverse link transformation # par() # view current settings opar &lt;- par() # make a copy of current settings par(mfrow = c(2, 2), mar = c(5,4,2,2), cex.main = 1) curve(plogis(beta0 + beta1*x), -1, 1, col = &quot;red&quot;, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Altitud&quot;, ylab = &quot;psi&quot;, lwd = 2) text(0.9, 0.95, &quot;A&quot;, cex = 1.5) plot(elev, psi, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Altitud&quot;, ylab = &quot;&quot;) text(0.9, 0.95, &quot;B&quot;, cex = 1.5) curve(plogis(beta0 + beta2*x), -1, 1, col = &quot;red&quot;, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Forest cover&quot;, ylab = &quot;psi&quot;, lwd = 2) text(-0.9, 0.95, &quot;C&quot;, cex = 1.5) plot(forest, psi, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Forest cover&quot;, ylab = &quot;&quot;) text(-0.9, 0.95, &quot;D&quot;, cex = 1.5) Figure 4.1: Two ways to show the relationship between the probability of occurrence of tapir and the covariates. (A) Relationship between psi and elevation for a constant value (mean equal to zero) of forest cover. (B) Relationship between psi and elevation in an observed value of forest cover. (C) Forest cover psi ratio for a constant elevation (at mean zero). (D) Relationship psi forest cover for the observed value of elevation. # dev.off() par(opar) # restore original par settings To better show the joint relationship between the two covariates and psi, we need to make a surface plot. Here we have not changed anything about the simulation, we have only added more data to it to better visualize it. # Compute expected occurrence for a grid of elevation and forest cover cov1 &lt;- seq(-1, 1, , 100) # Values for elevation cov2 &lt;- seq(-1, 1, , 100) # Values for forest cover psi.matrix &lt;- array(NA, dim = c(100, 100)) # Prediction matrix, for every # combination of values of elevation and forest cover for(i in 1:100){ for(j in 1:100){ psi.matrix[i, j] &lt;- plogis(beta0 + beta1 * cov1[i] + beta2 * cov2[j] + beta3 * cov1[i] * cov2[j] ) } } mapPalette &lt;- colorRampPalette(c(&quot;grey&quot;, &quot;yellow&quot;, &quot;orange&quot;, &quot;red&quot;)) image(x = cov1, y = cov2, z = psi.matrix, col = mapPalette(100), xlab = &quot;Altitud&quot;, ylab = &quot;Forest cover&quot;, cex.lab = 1.2) contour(x = cov1, y = cov2, z = psi.matrix, add = TRUE, lwd = 1) matpoints(elev, forest, pch=&quot;+&quot;, cex=0.8) Figure 4.2: Relationship constructed between the simulated data of the expected occurrence (occupation) of tapir (psi) represented with the color scale from gray to red, against elevation and forest cover simultaneously. In this case the interaction between the two covariates is given by the value of beta3 = 1 that we have established previously. So far we have not introduced any stochastic variation in the relationship between tapir occurrence and covariates. To do this we must make use of some statistical models, or statistical distributions, to describe the random variability around the expected value of psi. The typical way to introduce this random variation is to obtain the occurrence of tapir at each site i, \\(z _{i}\\) , from a Bernoulli distribution with the expected values (\\(\\psi _{i}\\)). 4.2.1 Why Bernoulli? In the ecological process \\(z _{i}\\) tapir occurrence is represented by a Bernoulli-type distribution where tapir is present at a site represented as the occupancy \\(\\psi\\) at a site where it is present, or not present 1-\\(\\psi\\). The Bernoulli distribution is a special case of the binomial distribution, and its best example is a single toss of a coin. If you require a more extensive, basic, detailed explanation and with more examples, I recommend you visit khanacademy. z &lt;- rbinom(n = M, size = 1, prob = psi) # Realised occurrence. A Bernoulli sum(z) # Total number of occupied sites ## [1] 40 table(z) # Frequency distribution of tapir occurrence ## z ## 0 1 ## 20 40 Here we have created the result of the ecological process: site-specific occurrence \\(z _{1}\\). We see that 20 sites are not occupied and the remaining 40 sites are occupied 4.3 Simulating the observation process and its result: the detection Occurrence z is not what we normally see, as there is a chance that we will fail to observe an individual. Hence there is a binary measure of error when we measure occurrence (we observe it or we dont observe it). We assume that we can make only one of the two possible sightings (yes, no), but we may have missed a tapir sighting somewhere, so the probability of detection is less than one, and the error measure is affected by coverage. of forest and temperature. Keep in mind that we will never register the presence of a tapir when in fact there are no tapir. In other words, we are assuming that we have no false positives. To make it explicit that we have an interaction effect between two covariates in our data, we are going to allow an interaction effect in the code, but set it to zero and thus have no effect in the model that generates the data. We first select the values for \\(\\alpha _{0}\\) to \\(\\alpha _{3}\\), where the first is the probability of detection for the tapir, on the logit scale, when all detection covariates have a value of zero. We have chosen the intercept of the detection model and then transformed it with the plogis link function. This is not the same as the average detection probability, which is higher in our simulation model, as we will see later. mean.detection &lt;- 0.3 # Mean expected detection alpha0 &lt;- qlogis(mean.detection) # same on logit scale (intercept) alpha1 &lt;- -1 # Effect (slope) of elevation alpha2 &lt;- -3 # Effect (slope) of temperature alpha3 &lt;- 0 # Interaction effect (slope) of elevevation and temperature Applying the linear model, we have the logit of the detection probability of the tapir for each site and sampling, and applying the inverse transformation (plogis), we obtain a matrix of dimensions 60 by 30 with the probability of detection for each site i and sampling j. Finally, we plot the relationships for the probability of detection in the data. logit.p &lt;- alpha0 + alpha1 * elev + alpha2 * temp + alpha3 * elev * temp p &lt;- plogis(logit.p) # Inverse link transform mean(p) # average per-site p is about 0.39 ## [1] 0.3928068 par(mfrow = c(2, 2), mar = c(5,4,2,2), cex.main = 1) curve(plogis(alpha0 + alpha1*x), -1, 1, col = &quot;red&quot;, frame.plot = FALSE, ylim = c(0, 1.1), xlab = &quot;Altitud&quot;, ylab = &quot;p&quot;, lwd = 2) text(-0.9, 1.05, &quot;A&quot;, cex = 1.5) matplot(elev, p, pch = &quot;*&quot;, frame.plot = FALSE, ylim = c(0, 1.1), xlab = &quot;Altitud&quot;, ylab = &quot;&quot;) text(-0.9, 1.05, &quot;B&quot;, cex = 1.5) curve(plogis(alpha0 + alpha2*x), -1, 1, col = &quot;red&quot;, frame.plot = FALSE, ylim = c(0, 1.1), xlab = &quot;Temperature&quot;, ylab = &quot;p&quot;, lwd = 2) text(-0.9, 1.05, &quot;C&quot;, cex = 1.5) matplot(temp, p, pch = &quot;*&quot;, frame.plot = FALSE, ylim = c(0, 1.1), xlab = &quot;Temperature&quot;, ylab = &quot;p&quot;) text(-0.9, 1.05, &quot;D&quot;, cex = 1.5) Figure 4.3: Two ways to show the relationships between the expected detection probability of the tapir (p) and the two variables elevation and temperature. (A) Relationship p and elevation for constant temperature (at the mean value, which is equal to zero). (B) Relationship between p and elevation in the observed value of temperature quantity. (C) Relationship between p and temperature for a constant value of elevation (at mean elevation equal to zero). (D) Relationship between p and temperature for an observed value of elevation. In a similar way we are going to produce a graph of a surface with the joint relationship between elevation, temperature and the probability of detection of the tapir (p), acting simultaneously. The relationship on the logarithmic scale is represented by a sloped plane that represents the interaction between elevation and forest cover. # Compute expected detection probability for a grid of elevation and temperature cov1 &lt;- seq(-1, 1,,100) # Values of elevation cov2 &lt;- seq(-1,1,,100) # Values of temperature p.matrix &lt;- array(NA, dim = c(100, 100)) # Prediction matrix which combines # every value in cov 1 with every other in cov2 for(i in 1:100){ for(j in 1:100){ p.matrix[i, j] &lt;- plogis(alpha0 + alpha1 * cov1[i] + alpha2 * cov2[j] + alpha3 * cov1[i] * cov2[j]) } } image(x = cov1, y = cov2, z = p.matrix, col = mapPalette(100), xlab = &quot;Altitud&quot;, ylab = &quot;Temperature&quot;, cex.lab = 1.2) contour(x = cov1, y = cov2, z = p.matrix, add = TRUE, lwd = 1) matpoints(elev, temp, pch=&quot;+&quot;, cex=0.7, col = &quot;black&quot;) Figure 4.4: Relationship constructed between the simulated data of the expected probability of detection (detectability) of tapir (p) represented with the color scale from gray to red, against elevation and temperature simultaneously. In this case, the interaction between the two covariates has a linear relationship that is given by the value of alpha3 = 0 that we have previously established. So far we have modeled the two processes, the ecological \\(z\\) and the observation process p separately. Now we will have to put them together, and for this we multiply the result of the ecological process by the probability of detection within a Bernoulli distribution. 4.3.1 Uniting the two processes the ecological and the observation When we measure the occurrence, the imperfect detection represents a source of error with a Bernoulli-type distribution (for example, the presence of the deer in a place where it is detected with a probability p, or it is not detected as 1-p) . By applying this observation process we produce repeated measures of the presence or absence (1 or 0) of deer at each site. Remember that the Bernoulli distribution is a special case of the binomial distribution, and its best example is a single coin toss. Right now we are establishing the hierarchy in the hierarchical model. Here we are nesting the ecological process within the observation process. y &lt;- matrix(NA, nrow = M, ncol = J) # Prepare array for counts for (i in 1:J){ # Generate counts y[,i] &lt;- rbinom(n = M, size = 1, prob = z*p[,i]) # this is the Bernoulli } So far we have simulated the presence/absence of mountain tapirs at 60 sites during 30 sampling sessions. Lets see what the tables contain. Remember that the sites are in the rows and the repeated samples in the columns. For comparison, we will show the true occurrence in the first column for 30 sites and only five samples. library(knitr) kable(as.data.frame(head(cbind(&quot;True Presence/Absence&quot; = z, &quot;1st survey&quot; = y[,1], &quot;2nd survey&quot; = y[,2], &quot;3rd survey&quot; = y[,3], &quot;4th survey&quot; = y[,4], &quot;5th survey&quot; = y[,5]), 30)) ) # First 30 rows (= sites) True Presence/Absence 1st survey 2nd survey 3rd survey 4th survey 5th survey 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 Now we will finally visualize graphically the data of ones and zeros that we have simulated for our sampling. Remember that these are values of ones that represent whether or not we have detected the tapir at each of the sampling sites on each of the visits. par(mfrow = c(2, 2), mar = c(5,4,2,2), cex.main = 1) matplot(elev, jitter(y), pch = &quot;*&quot;, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Elevation&quot;, ylab = &quot;Detection/Nondetection (y)&quot;) matplot(forest, jitter(y), pch = &quot;*&quot;, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Forest cover&quot;, ylab = &quot;Detection/Nondetection (y)&quot;) matplot(temp, jitter(y), pch = &quot;*&quot;, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Temperature&quot;, ylab = &quot;Detection/Nondetection (y)&quot;) hist(y, breaks = 50, col = &quot;grey&quot;, ylim = c(0, 600), main = &quot;&quot;, xlab = &quot;Detection/Nondetection (y)&quot;) Figure 4.5: Relationship between observed (jittered) tapir occupancy (y) and the three standardized covariates. Elevation (A). Forest cover (B). Temperature (C) and the frequency of distribution of the observed occurrence (y) in a data set of 60 sites with 30 samples each (D). So far we have created a data set where tapir detection/non-detection is negatively correlated with temperature and positively correlated with forest cover. There is a reason why this correlation between variables is different. Occurrence per site, the target of ecological inference, is affected by forest cover and elevation, but not by temperature, while the probability of detection, the parameter characterizing the measurement of the error process when we take occurrence measurements, is also affected by elevation and additionally by temperature. Therefore, as can be seen, there is a great challenge to be able to disentangle the reason for the Spatio-temporal variation in the observation of the detection/non-detection data, given that they can be affected by two totally different processes: the ecological and the observational, that the same covariate can also affect the two processes and that there can also be interactions between those covariates. References Kéry, M. (2008). Estimating abundance from bird counts: binomial mixture models uncover complex covariate relationships. The Auk, 125(2), 336345. doi: 10.1525/auk.2008.06185 Kéry, M., &amp; Royle, J. A. (2008). Hierarchical Bayes estimation of species richness and occupancy in spatially replicated surveys. Journal of Applied Ecology, 45(2), 589598. doi: 10.1111/j.1365-2664.2007.01441.x Kéry, Marc, &amp; Schaub, M. (2012). Estimation of Occupancy and Species Distributions from Detection/Nondetection Data in Metapopulation Designs Using Site-Occupancy Models. In Bayesian population analysis using WinBUGS (pp. 413461). Elsevier. doi: 10.1016/B978-0-12-387020-9.00013-4 R Core Team. (2016). R: A language and environment for statistical computing. Vienna, Austria: R Foundation for Statistical Computing. Retrieved from http://www.r-project.org/ "],["function1.html", "Chapter5 Packing everything into a function", " Chapter5 Packing everything into a function It could be very useful to pack everything weve done into a single function that allows us to do the same thing many times over and over again. This will allow us to design simulations in a more concise and flexible way and makes the generation of parameters used to generate data more transparent. So lets define a function (which well call data.fn) to generate the same data type we just created, assigning arguments to the function, such as sample size, covariate effects, and interaction directions and magnitudes. of the detection error and occupancy terms. This will make our code more flexible and efficient. ############################### ## The function starts here ### ############################### # Function definition with set of default values data.fn &lt;- function(M = 60, J = 30, mean.occupancy = 0.6, beta1 = -2, beta2 = 2, beta3 = 1, mean.detection = 0.3, alpha1 = -1, alpha2 = -3, alpha3 = 0, show.plot = TRUE){ # Function to simulate occupancy measurements replicated at M sites during J occasions. # Population closure is assumed for each site. # Expected occurrence may be affected by elevation (elev), # forest cover (forest) and their interaction. # Expected detection probability may be affected by elevation, # temperature (temp) and their interaction. # Function arguments: # M: Number of spatial replicates (sites) # J: Number of temporal replicates (occasions) # mean.occupancy: Mean occurrence at value 0 of occurrence covariates # beta1: Main effect of elevation on occurrence # beta2: Main effect of forest cover on occurrence # beta3: Interaction effect on occurrence of elevation and forest cover # mean.detection: Mean detection prob. at value 0 of detection covariates # alpha1: Main effect of elevation on detection probability # alpha2: Main effect of temperature on detection probability # alpha3: Interaction effect on detection of elevation and temperature # show.plot: if TRUE, plots of the data will be displayed; # set to FALSE if you are running simulations. # Create covariates elev &lt;- runif(n = M, -1, 1) # Scaled elevation forest &lt;- runif(n = M, -1, 1) # Scaled forest cover temp &lt;- array(runif(n = M*J, -1, 1), dim = c(M, J)) # Scaled temperature # Model for occurrence beta0 &lt;- qlogis(mean.occupancy) # Mean occurrence on link scale psi &lt;- plogis(beta0 + beta1*elev + beta2*forest + beta3*elev*forest) z &lt;- rbinom(n = M, size = 1, prob = psi) # Realised occurrence # Plots if(show.plot){ par(mfrow = c(2, 2), cex.main = 1) devAskNewPage(ask = TRUE) curve(plogis(beta0 + beta1*x), -1, 1, col = &quot;red&quot;, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Elevation&quot;, ylab = &quot;psi&quot;, lwd = 2) plot(elev, psi, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Elevation&quot;, ylab = &quot;&quot;) curve(plogis(beta0 + beta2*x), -1, 1, col = &quot;red&quot;, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Forest cover&quot;, ylab = &quot;psi&quot;, lwd = 2) plot(forest, psi, frame.plot = FALSE, ylim = c(0, 1), xlab = &quot;Forest cover&quot;, ylab = &quot;&quot;) } # Model for observations y &lt;- p &lt;- matrix(NA, nrow = M, ncol = J)# Prepare matrix for y and p alpha0 &lt;- qlogis(mean.detection) # mean detection on link scale for (j in 1:J){ # Generate counts by survey p[,j] &lt;- plogis(alpha0 + alpha1*elev + alpha2*temp[,j] + alpha3*elev*temp[,j]) y[,j] &lt;- rbinom(n = M, size = 1, prob = z * p[,j]) } # True and observed measures of &#39;distribution&#39; sumZ &lt;- sum(z) # Total occurrence (all sites) sumZ.obs &lt;- sum(apply(y,1,max)) # Observed number of occ sites psi.fs.true &lt;- sum(z) / M # True proportion of occ. sites in sample psi.fs.obs &lt;- mean(apply(y,1,max)) # Observed proportion of occ. sites in sample # More plots if(show.plot){ par(mfrow = c(2, 2)) curve(plogis(alpha0 + alpha1*x), -1, 1, col = &quot;red&quot;, main = &quot;Relationship p-elevation \\nat average temperature&quot;, xlab = &quot;Scaled elevation&quot;, frame.plot = F) matplot(elev, p, xlab = &quot;Scaled elevation&quot;, main = &quot;Relationship p-elevation\\n at observed temperature&quot;, pch = &quot;*&quot;, frame.plot = F) curve(plogis(alpha0 + alpha2*x), -1, 1, col = &quot;red&quot;, main = &quot;Relationship p-temperature \\n at average elevation&quot;, xlab = &quot;Scaled temperature&quot;, frame.plot = F) matplot(temp, p, xlab = &quot;Scaled temperature&quot;, main = &quot;Relationship p-temperature \\nat observed elevation&quot;, pch = &quot;*&quot;, frame.plot = F) } # Output return(list(M = M, J = J, mean.occupancy = mean.occupancy, beta0 = beta0, beta1 = beta1, beta2 = beta2, beta3 = beta3, mean.detection = mean.detection, alpha0 = alpha0, alpha1 = alpha1, alpha2 = alpha2, alpha3 = alpha3, elev = elev, forest = forest, temp = temp, psi = psi, z = z, p = p, y = y, sumZ = sumZ, sumZ.obs = sumZ.obs, psi.fs.true = psi.fs.true, psi.fs.obs = psi.fs.obs)) } ############################### ## The function ends here ### ############################### Once we have defined the function and executed its code, we can call it repeatedly and output the results to the screen or assign them to an object in R. So that we can use the dataset stored in the object for detailed analysis. # Run this part line by line, taking note of the meaning of the # model in the comment and hitting Enter after each graph. # Take in to account that if you do not override all the parameters # with another value, the function will use the default values. data.fn() # Execute function with default arguments data.fn(show.plot = FALSE) # same, without plots objeto1 &lt;- data.fn(M = 30, J = 10, mean.occupancy = 0.5, beta1 = -2, beta2 = 2, beta3 = 1, mean.detection = 0.25, alpha1 = -1, alpha2 = -3, alpha3 = 0, show.plot = TRUE) # Explicit defaults Perhaps the simplest possible use for this function is to experience the sampling error by firsthand: which is the natural variability from repeated runs (several data sets) of our stochastic process by which we compute the data sets. We are going to simulate 10,000 tapir data sets to see how they vary in terms of the true number of occupied sites (sumZ in the code) and the number of sites where tapirs were observed at least once. Note that the data generated in the 10,000 has default parameters in the mean.occupancy and mean.detection parameters. simrep &lt;- 10000 trueSumZ &lt;- obsSumZ &lt;- numeric(simrep) for(i in 1:simrep){ if(i %% 1000 ==0 ) # report progress cat(&quot;iter&quot;, i, &quot;\\n&quot;) data &lt;- data.fn(M = 60,J = 3,show.plot = FALSE) # 60 sitios, 3 muestreos, p=0.3 trueSumZ[i] &lt;- data$sumZ obsSumZ[i] &lt;- sum(apply(data$y, 1, max)) } ## iter 1000 ## iter 2000 ## iter 3000 ## iter 4000 ## iter 5000 ## iter 6000 ## iter 7000 ## iter 8000 ## iter 9000 ## iter 10000 plot(sort(trueSumZ), ylim = c(min(obsSumZ), max(trueSumZ)), ylab = &quot;&quot;, xlab = &quot;Simulation&quot;, col = &quot;red&quot;, main = &quot;True (red) and observed (blue) number of occupied sites&quot;) points(obsSumZ[order(trueSumZ)], col = &quot;blue&quot;) Figure 5.1: Natural variability (sampling error) of the true number of occupied sites (ordered by size) in red and the observed number of occupied sites (in blue). The number of sites observed/total is also known as the naïve occupancy of deer occurrence at 60 sites in the simulation. The width of the blue area represents the error induced by imperfect detection. Note the importance of taking this error into account to get a better idea of the occupation. As an exercise, change the code to again generate the 10,000 simulations with medium (mean.detection =0.5), high (mean.detection =0.8), and perfect detection (mean.detection =1). Compare the resulting graphs. Now we can use this function to generate data under different sampling schemes, varying the number of sites and the number of repeated samples. As well as under different ecological and detection characteristics, and considering possible interactions between covariates. # Run this part line by line, taking note of the meaning of the # model in the comment and hitting Enter after each graph. # Take in to account that if you do not override all the parameters # with another value, the function will use the default values. data.fn(J = 1, show.plot = T) # Only 1 survey (no temporal replicate) data.fn(J = 2, show.plot = T) # Only 2 surveys (sites) data.fn(M = 5, J = 3) # Only 5 sites, 3 counts (repeted visits) data.fn(M = 1, J = 100) # No spatial replicates, but 100 counts data.fn(M = 1000, J = 100) # Very intensive sampling. 1000 sites, 100 visits data.fn(mean.occupancy = 0.6, # psi = 0.6 and mean.detection = 1, # p = 1 (perfect detection!!!) show.plot = T) data.fn(mean.occupancy = 0.95, # psi = 1 a really coomon sp. mean.detection = 1, # p = 1 (perfect detection!!!) show.plot = T) data.fn(mean.occupancy = 0.05, # psi = 0.05 a really rare sp. mean.detection = 0.05, # p = 0.05 and very hard to detect !!! show.plot = T) data.fn(beta3 = 1.5, show.plot = TRUE) # With interaction elev-temp on p data.fn(mean.occupancy = 0.6, beta1 = -2, beta2 = 2, beta3 = 1, mean.detection = 0.1, show.plot = TRUE) # p = 1 (low detectability) data.fn(M = 267, J = 5, mean.occupancy = 0.6, beta1 = 0, beta2 = 0, beta3 = 0, mean.detection = 0.4, alpha1 = 0, alpha2 = 0, alpha3 = 0, show.plot = TRUE) # Simplest case with occupancy (0.6) and detection (0.4) constant, no covariate effects # observe betas = 0, and alphas = 0. This correspond to a kind of null model. CONGRATULATIONS!!!, if you got this far, and if you understood the data simulation and its procedure, then you fully understood the basic occupancy model, which is the cornerstone of modern biological sampling and monitoring. "],["unmarked.html", "Chapter6 Occupancy analysis, ML method 6.1 Generating the data 6.2 Putting the data in unmarked 6.3 Fitting the models 6.4 Model Selection 6.5 Prediction in graphs 6.6 Spatially explicit prediction", " Chapter6 Occupancy analysis, ML method Now that we have understood how the two processes work and interact; the ecological and the observational to produce the occupation data. After generating several data sets, now we only have to analyze them. The most direct and intuitive way is to use the occu function from the unmarked (Fiske &amp; Chandler, 2011) package. Later we can use a Bayesian type model in the BUGS language to analyze the same data and in the end compare which of the two estimators, Maximum Likelihood or Bayesian, is closer to the true parameters. 6.0.1 Clearing R memory Before we continue, and since we have already generated a large amount of data and models in the previous steps, we are going to clear the memory of R before we begin. We do this with the command: rm(list = ls()) Once we have done this we must re-run the code of the function that generates the data that we have created in Chapter 5. After having loaded the function again we must return to 6.1 Generating the data This time we will use a TEAM-type design (https://www.wildlifeinsights.org/team-network) with 60 sampling sites and 30 repeated visits, which is equivalent to the 30 days that the cameras remain active in the field. Again our species is the white-tailed tapir. For this example we will assume that detection is 0.6, occupancy is 0.8, and the interactions are much simpler with elevation as the only covariate explaining occupancy. However, for detection there is a more complex relationship, assuming that there is a slight interaction between the observation covariates. For observation, elevation and temperature interact with each other. Also, note how elevation influences in opposite directions with a positive sign at elevation for detection and negative for occupancy. # Data generation # Lets build a model were elevation explain occupancy and p has interactions datos2&lt;-data.fn(M = 60, J = 30, show.plot = FALSE, mean.occupancy = 0.8, beta1 = -1.5, beta2 = 0, beta3 = 0, mean.detection = 0.6, alpha1 = 2, alpha2 = 1, alpha3 = 1.5 ) # Function to simulate occupancy measurements replicated at M sites during J occasions. # Population closure is assumed for each site. # Expected occurrence may be affected by elevation (elev), # forest cover (forest) and their interaction. # Expected detection probability may be affected by elevation, # temperature (temp) and their interaction. # Function arguments: # M: Number of spatial replicates (sites) # J: Number of temporal replicates (occasions) # mean.occupancy: Mean occurrence at value 0 of occurrence covariates # beta1: Main effect of elevation on occurrence # beta2: Main effect of forest cover on occurrence # beta3: Interaction effect on occurrence of elevation and forest cover # mean.detection: Mean detection prob. at value 0 of detection covariates # alpha1: Main effect of elevation on detection probability # alpha2: Main effect of temperature on detection probability # alpha3: Interaction effect on detection of elevation and temperature # show.plot: if TRUE, plots of the data will be displayed; # set to FALSE if you are running simulations. #To make the objects inside the list directly accessible to R, without having to address #them as data$C for instance, you can attach datos2 to the search path. attach(datos2) # Make objects inside of &#39;datos2&#39; accessible directly #Remember to detach the data after use, and in particular before attaching a new data #object, because more than one data set attached in the search path will cause confusion. # detach(datos2) # Make clean up 6.2 Putting the data in unmarked Unmarked is the R package we use to analyze the (Fiske &amp; Chandler, 2011) occupancy data. To achieve this we must first prepare the data and collect it in an object of type unmarkedFrame. In this case we use the unmarkedFrameOccu function, which is specific for occupancy analysis of a single season or season. More about unmarked at: https://sites.google.com/site/unmarkedinfo/home library(unmarked) siteCovs &lt;- as.data.frame(cbind(forest,elev)) # occupancy covariates obselev&lt;-matrix(rep(elev,J),ncol = J) # make elevation per observation obsCovs &lt;- list(temp= temp,elev=obselev) # detection covariates # umf is the object joining observations (y), occupancy covariates (siteCovs) # and detection covariates (obsCovs). Note that obsCovs should be a list of # matrices or dataframes. umf &lt;- unmarkedFrameOccu(y = y, siteCovs = siteCovs, obsCovs = obsCovs) The unmarked package allows us to graphically see how the data is arranged at the sampling sites with the plot function. plot (umf) Figure 6.1: Inspección grafica del objeto umf. 6.3 Fitting the models The next step is to fit the models that were required by varying the covariates. This is accomplished with the occu() function. Keep in mind that in the model building process your models must have a biological meaning. # detection first, occupancy next fm0 &lt;- occu(~1 ~1, umf) # Null model fm1 &lt;- occu(~ elev ~ 1, umf) # elev explaining detection fm2 &lt;- occu(~ elev ~ elev, umf) # elev explaining detection and occupancy fm3 &lt;- occu(~ temp ~ elev, umf) fm4 &lt;- occu(~ temp ~ forest, umf) fm5 &lt;- occu(~ elev + temp ~ 1, umf) fm6 &lt;- occu(~ elev + temp + elev:temp ~ 1, umf) fm7 &lt;- occu(~ elev + temp + elev:temp ~ elev, umf) fm8 &lt;- occu(~ elev + temp + elev:temp ~ forest, umf) 6.4 Model Selection Unmarked allows you to perform a model selection procedure to select models based on the Akaike information Criterium (AIC) of each one. So the lowest AIC is the most parsimonious model according to our data (Burnham &amp; Anderson, 2004). models &lt;- fitList( # here e put names to the models &#39;p(.)psi(.)&#39; = fm0, &#39;p(elev)psi(.)&#39; = fm1, &#39;p(elev)psi(elev)&#39; = fm2, &#39;p(temp)psi(elev)&#39; = fm3, &#39;p(temp)psi(forest)&#39; = fm4, &#39;p(temp+elev)psi(.)&#39; = fm5, &#39;p(temp+elev+elev:temp)psi(.)&#39; = fm6, &#39;p(temp+elev+elev:temp)psi(elev)&#39; = fm7, &#39;p(temp+elev+elev:temp)psi(forest)&#39; = fm8) modSel(models) # model selection procedure ## nPars AIC delta AICwt cumltvWt ## p(temp+elev+elev:temp)psi(elev) 6 1630.77 0.00 9.2e-01 0.92 ## p(temp+elev+elev:temp)psi(.) 5 1636.27 5.49 5.9e-02 0.98 ## p(temp+elev+elev:temp)psi(forest) 6 1638.24 7.47 2.2e-02 1.00 ## p(temp+elev)psi(.) 4 1672.55 41.78 7.8e-10 1.00 ## p(elev)psi(elev) 4 1741.34 110.57 9.0e-25 1.00 ## p(elev)psi(.) 3 1746.83 116.06 5.8e-26 1.00 ## p(temp)psi(elev) 4 1898.56 267.79 6.5e-59 1.00 ## p(temp)psi(forest) 4 1906.03 275.26 1.6e-60 1.00 ## p(.)psi(.) 2 1969.25 338.48 2.9e-74 1.00 6.5 Prediction in graphs The model with the lowest AIC can be used to predict expected results according to a new data set. For example, one might ask the expected abundance of deer at a higher elevation site. Predictions are also another way of presenting the results of an analysis. Here we will illustrate what the prediction of \\(\\psi\\) and p looks like over the range of covariates studied. Note that we are using standardized covariates. If we were using covariates at their real scale, we would have to take into account that they have to be transformed using the mean and standard deviation. Before using the model to predict it is a good idea to check the model parameters and their errors, then check graphically that the model fits well with the parboot function, which does a resampling of the model. This plot is interpreted as the model having a good fit, when the mean (dotted line) is between the intervals of the histogram. If the line is too far from the histogram the model might not be good at predicting. summary(fm7) # see the model parameters ## ## Call: ## occu(formula = ~elev + temp + elev:temp ~ elev, data = umf) ## ## Occupancy (logit-scale): ## Estimate SE z P(&gt;|z|) ## (Intercept) 1.41 0.366 3.85 0.000117 ## elev -1.63 0.656 -2.48 0.013082 ## ## Detection (logit-scale): ## Estimate SE z P(&gt;|z|) ## (Intercept) 0.53 0.0698 7.60 3.04e-14 ## elev 1.80 0.1277 14.10 3.56e-45 ## temp 1.16 0.1209 9.57 1.08e-21 ## elev:temp 1.33 0.2211 6.00 1.96e-09 ## ## AIC: 1630.771 ## Number of sites: 60 ## optim convergence code: 0 ## optim iterations: 31 ## Bootstrap iterations: 0 pb &lt;- parboot(fm7, nsim=250, report=10) # goodness of fit ## t0 = 409.3793 plot (pb) # plot goodness of fit Figure 6.2: Graphical evaluation of the model fit fm7. Now that we know that our best model has a good fit, we can use it to predict occupancy in the altitude range to see how it behaves on a graph. elevrange&lt;-data.frame(elev=seq(min(datos2$elev),max(datos2$elev),length=100)) # newdata pred_psi &lt;-predict(fm7,type=&quot;state&quot;,newdata=elevrange,appendData=TRUE) plot(Predicted~elev, pred_psi,type=&quot;l&quot;,col=&quot;blue&quot;, xlab=&quot;elev&quot;, ylab=&quot;psi&quot;) lines(lower~elev, pred_psi,type=&quot;l&quot;,col=gray(0.5)) lines(upper~elev, pred_psi,type=&quot;l&quot;,col=gray(0.5)) Figure 6.3: Plot of occupancy versus elevation. 6.6 Spatially explicit prediction We can also use the best model to predict spatially explicitly if we have the maps. As an illustration we will construct simulated maps for each of our covariates. The maps arise from a random pattern of points with a Poisson distribution. We then convert these points to an interpolated surface. # lets make random maps for the three covariates library(raster) library(spatstat) set.seed(24) # Remove for random simulations # CONSTRUCT ANALYSIS WINDOW USING THE FOLLOWING: xrange=c(-2.5, 1002.5) yrange=c(-2.5, 502.5) window&lt;-owin(xrange, yrange) # Build maps from random points and interpole in same line elev &lt;- density(rpoispp(lambda=0.6, win=window)) # forest &lt;- density(rpoispp(lambda=0.2, win=window)) # temp &lt;- density(rpoispp(lambda=0.5, win=window)) # # Convert covs to raster and Put in the same stack mapdata.m&lt;-stack(raster(elev),raster(forest), raster(temp)) names(mapdata.m)&lt;- c(&quot;elev&quot;, &quot;forest&quot;, &quot;temp&quot;) # put names to raster # lets plot the covs maps plot(mapdata.m) Figure 6.4: Simulated map of elevation, forest and temperature. Once we have our covariate maps, we use them to predict with the best model. In this way we can have a map with predictions of the occupancy and the probability of detection. # make the predictions predictions_psi &lt;- predict(fm7, type=&quot;state&quot;, newdata=mapdata.m) # predict psi ## doing row 1000 of 16384 ## doing row 2000 of 16384 ## doing row 3000 of 16384 ## doing row 4000 of 16384 ## doing row 5000 of 16384 ## doing row 6000 of 16384 ## doing row 7000 of 16384 ## doing row 8000 of 16384 ## doing row 9000 of 16384 ## doing row 10000 of 16384 ## doing row 11000 of 16384 ## doing row 12000 of 16384 ## doing row 13000 of 16384 ## doing row 14000 of 16384 ## doing row 15000 of 16384 ## doing row 16000 of 16384 predictions_p &lt;- predict(fm7, type=&quot;det&quot;, newdata=mapdata.m) # predict p ## doing row 1000 of 16384 ## doing row 2000 of 16384 ## doing row 3000 of 16384 ## doing row 4000 of 16384 ## doing row 5000 of 16384 ## doing row 6000 of 16384 ## doing row 7000 of 16384 ## doing row 8000 of 16384 ## doing row 9000 of 16384 ## doing row 10000 of 16384 ## doing row 11000 of 16384 ## doing row 12000 of 16384 ## doing row 13000 of 16384 ## doing row 14000 of 16384 ## doing row 15000 of 16384 ## doing row 16000 of 16384 # put in the same stack predmaps&lt;-stack(predictions_psi$Predicted,predictions_p$Predicted) names(predmaps)&lt;-c(&quot;psi_predicted&quot;, &quot;p_predicted&quot;) # put names plot(predmaps) Figure 6.5: Spatially explicit detection and occupancy models. References Burnham, K. P., &amp; Anderson, D. R. (2004). Information and likelihood theory: A basis for model selection and inference. In K. P. Burnham &amp; D. R. Anderson (Eds.), Model selection and multimodel inference: A practical information-theoretic approach (pp. 4997). New York: Springer New York. Retrieved from http://link.springer.com/chapter/10.1007%2F978-0-387-22456-5_2 Fiske, I., &amp; Chandler, R. (2011). unmarked : An R Package for fitting hierarchical models of wildlife occurrence and abundance. Journal of Statistical Software, 43(10), 123. doi: 10.18637/jss.v043.i10 "],["bayesian.html", "Chapter7 Bayesian analysis 7.1 Generating the data 7.2 Comparing the actual and estimated values from ML and Bayesian 7.3 Bayesian estimates easily", " Chapter7 Bayesian analysis In this part we are going to estimate the same parameters of a model equal to the best model which was selected in the unmarked model selection procedure in the previous chapter. Recall that this model has beta1 and alpha1, alpha2, alpha3. The parameters that we will estimate with the Bayesian method are going to be compared with the parameters that we already estimated with ML in unmarked and we will also compare them with the real parameters that we defined when establishing the data (data2) with the function data.fn, to see which of the two estimation methods (ML or Bayesian) are closer to the real parameters. 7.1 Generating the data Again we will use a TEAM-type design (https://www.wildlifeinsights.org/team-network) with 60 sampling sites and 30 repeated visits, which is equivalent to the 30 days that the cameras remain active in the field. Our species remains the same, the white-tailed deer. For this example we will assume that detection is 0.6, occupancy is 0.8, and the interactions are simple with altitude as the only covariate explaining occupancy. But for detection there is a more complex relationship, assuming there is a slight interaction between the observation covariates. For observation, altitude and temperature interact with each other. Also note how altitude influences in opposite directions with a positive altitude sign for detection and a negative sign for occupancy. # ### Generate a new data set or use the same # # **************************************** # set.seed(148) # data &lt;- data.fn(show.plot = T) # Default arguments # str(data) # Look at the object # we are oing to use the data from datos2 object ### Fit same model with JAGS, using library jagsUI # ************************************************ # Bundle data win.data &lt;- list(y = datos2$y, M = nrow(datos2$y), J = ncol(datos2$y), elev = datos2$elev, forest = datos2$forest, temp = datos2$temp) # str(win.data) # # Specify model in BUGS language # sink(&quot;model22.txt&quot;) # cat(&quot; # model { # # # Priors # mean.p ~ dunif(0, 1) # Detection intercept on prob. scale # alpha0 &lt;- logit(mean.p) # same on logit scale # mean.psi ~ dunif(0, 1) # Occupancy intercept on prob. scale # beta0 &lt;- logit(mean.psi) # same on logit scale # for(k in 1:3){ # 2 detection covariates + 1 interact # alpha[k] ~ dnorm(0, 0.01) # Covariates on logit(detection) # # alpha[k] ~ dnorm(0, 0.05) # Covariates on logit(detection) # # alpha[k] ~ dunif(-10, 10) # Covariates on logit(detection) # } # # for(k in 1:1){ # 2 occupancy covariates + 1 interact # beta[k] ~ dnorm(0, 0.01) # Covariates on logit(occupancy) # # beta[k] ~ dnorm(0, 0.05) # Covariates on logit(occupancy) # # beta[k] ~ dunif(-10, 10) # Covariates on logit(occupancy) # } # # # Translation of the occupancy parameters in unmarked into those for BUGS: # # (Intercept) (beta0 in BUGS) # # elev (beta[1]) # # forest (beta[2]) # # temp (beta[3]) # # elev:forest (beta[4]) # # elev:temp (beta[5]) # # forest:temp (beta[6]) # # elev:forest:temp (beta[7]) # # # # Likelihood # for (i in 1:M) { # # True state model for the partially observed true state # z[i] ~ dbern(psi[i]) # True occupancy z at site i # logit(psi[i]) &lt;- beta0 + # occupancy (psi) intercept # beta[1] * elev[i] #+ # elev # #beta[2] * forest[i] #+ # forest # #beta[3] * elev[i] * forest[i] # elev:forest # #beta[4] * elev[i] * temp[i] + # elev:temp # #beta[5] * temp[i] + # temp # #beta[6] * forest[i] * temp[i] + # forest:temp # #beta[7] * elev[i] * forest[i] * temp[i] # elev:forest:temp # # for (j in 1:J) { # # Observation model for the actual observations # y[i,j] ~ dbern(p.eff[i,j]) # Detection-nondetection at i and j # p.eff[i,j] &lt;- z[i] * p[i,j] # logit(p[i,j]) &lt;- alpha0 + # detection (p) intercept # alpha[1] * elev[i] + # effect of elevation on p # alpha[2] * temp[i,j] + # effect of temp on p # alpha[3] * elev[i] * temp[i,j] # effect of elev:temp on p # } # } # # # Derived quantities # sumZ &lt;- sum(z[]) # Number of occupied sites among those studied # occ.fs &lt;- sum(z[])/M # proportion of occupied sites among those studied # logit.psi &lt;- beta0 # For comparison with unmarked # logit.p &lt;- alpha0 # For comparison with unmarked # } # &quot;,fill = TRUE) # sink() library(jagsUI) # library(R2jags) # Initial values zst &lt;- apply(datos2$y, 1, max) inits &lt;- function(){list(z = zst, mean.psi = runif(1), mean.p = runif(1), alpha = rnorm(3), # adjust here beta = rnorm(1))} # adjust here # Parameters monitored params &lt;- c(&quot;sumZ&quot;, &quot;occ.fs&quot;, &quot;logit.psi&quot;, &quot;logit.p&quot;, &quot;alpha&quot;, &quot;beta&quot;) # MCMC settings # ni &lt;- 100000 ; nt &lt;- 10 ; nb &lt;- 1000 ; nc &lt;- 3 ni &lt;- 10000 ; nt &lt;- 10 ; nb &lt;- 500 ; nc &lt;- 3 # Call JAGS from R (ART 260 sec with norm(), 480 with unif(-10,10)) # and summarize posteriors system.time(out22 &lt;- jags(win.data, inits, parameters.to.save = params, model.file = &quot;D:/BoxFiles/Box Sync/CodigoR/Toshiba/IntroOccuBook/bookdown-demo-master/model22.txt&quot;, n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb, parallel = T)) ## ## Processing function input....... ## ## Done. ## ## Beginning parallel processing using 3 cores. Console output will be suppressed. ## ## Parallel processing completed. ## ## Calculating statistics....... ## ## Done. ## user system elapsed ## 0.04 0.02 233.16 # See model diagnistics and convergence library(mcmcplots) library(ggmcmc) fit22.mcmc &lt;- as.mcmc.list(out22$samples) bayes.mod.fit.gg &lt;- ggs(fit22.mcmc) #convert to ggmcmc ggs_running(bayes.mod.fit.gg)# check if chains approach target distrib. # denplot(fit22.mcmc, parms = c(&quot;beta&quot;, # &quot;alpha[1]&quot;, &quot;alpha[2]&quot;, &quot;alpha[3]&quot;, # &quot;logit.psi&quot;, &quot;logit.p&quot; )) # traplot(fit22.mcmc) # ggs_density(bayes.mod.fit.gg) # xyplot(out22) # assess within-chain convergence densityplot(out22) # shape of the posterior distribution # see model result and estimates print(out22, 3) ## JAGS output for model &#39;D:/BoxFiles/Box Sync/CodigoR/Toshiba/IntroOccuBook/bookdown-demo-master/model22.txt&#39;, generated by jagsUI. ## Estimates based on 3 chains of 10000 iterations, ## adaptation = 100 iterations (sufficient), ## burn-in = 500 iterations and thin rate = 10, ## yielding 2850 total samples from the joint posterior. ## MCMC ran in parallel for 3.884 minutes at time 2022-06-25 22:47:58. ## ## mean sd 2.5% 50% 97.5% overlap0 f Rhat n.eff ## sumZ 46.029 0.168 46.000 46.000 47.000 FALSE 1.000 1.000 2850 ## occ.fs 0.767 0.003 0.767 0.767 0.783 FALSE 1.000 1.000 2850 ## logit.psi 1.173 0.324 0.562 1.163 1.825 FALSE 1.000 1.000 2850 ## logit.p 0.408 0.074 0.263 0.407 0.560 FALSE 1.000 1.001 2372 ## alpha[1] 2.147 0.152 1.853 2.143 2.445 FALSE 1.000 1.000 2850 ## alpha[2] 0.902 0.126 0.657 0.903 1.155 FALSE 1.000 1.000 2850 ## alpha[3] 1.686 0.247 1.208 1.682 2.180 FALSE 1.000 1.000 2850 ## beta -1.475 0.632 -2.769 -1.458 -0.329 FALSE 0.995 1.000 2850 ## deviance 1589.362 3.508 1585.504 1588.480 1599.696 FALSE 1.000 1.000 2850 ## ## Successful convergence based on Rhat values (all &lt; 1.1). ## Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## For each parameter, n.eff is a crude measure of effective sample size. ## ## overlap0 checks if 0 falls in the parameter&#39;s 95% credible interval. ## f is the proportion of the posterior with the same sign as the mean; ## i.e., our confidence that the parameter is positive or negative. ## ## DIC info: (pD = var(deviance)/2) ## pD = 6.2 and DIC = 1595.517 ## DIC is an estimate of expected predictive error (lower is better). # store in tmp coefficients from best ML model tmp &lt;- summary(fm7) ## ## Call: ## occu(formula = ~elev + temp + elev:temp ~ elev, data = umf) ## ## Occupancy (logit-scale): ## Estimate SE z P(&gt;|z|) ## (Intercept) 1.18 0.326 3.62 0.000291 ## elev -1.41 0.624 -2.26 0.023548 ## ## Detection (logit-scale): ## Estimate SE z P(&gt;|z|) ## (Intercept) 0.407 0.0735 5.54 3.03e-08 ## elev 2.140 0.1494 14.32 1.66e-46 ## temp 0.900 0.1262 7.14 9.68e-13 ## elev:temp 1.680 0.2514 6.68 2.34e-11 ## ## AIC: 1656.533 ## Number of sites: 60 ## optim convergence code: 0 ## optim iterations: 38 ## Bootstrap iterations: 0 modestimates &lt;- cbind(rbind(tmp$state[1:2], tmp$det[1:2]), Post.mean = out22$summary[c(3, 8, 4:7), 1], Post.sd = out22$summary[c(3, 8, 4:7), 2] ) # fix the(logit-scale) in unmarked modestimates[1,1]&lt;- plogis(modestimates[1,1]) modestimates[3,1]&lt;- plogis(modestimates[3,1]) # fix the(logit-scale) in Bayes in logit.psi logit.p modestimates[1,3]&lt;- plogis(modestimates[1,3]) modestimates[3,3]&lt;- plogis(modestimates[3,3]) # get real values from datos2 object real&lt;- rbind(datos2$mean.occupancy, datos2$beta1, datos2$mean.detection, datos2$alpha1, datos2$alpha2, datos2$alpha3) 7.2 Comparing the actual and estimated values from ML and Bayesian Lets see how close the estimates are to the actual values, by comparing the actual value with the Maximum Likelihood estimate (columns 2 and 3) and the Bayesian estimate (columns 4 and 5). ### see if the values are close to real values compare &lt;- cbind(real, modestimates) # put both in same table # put names to rows rownames(compare) &lt;- c(&quot;psi&quot;,&quot;beta&quot;,&quot;p&quot;,&quot;alpha1&quot;,&quot;alpha2&quot;, &quot;alpha3&quot;) # print comparing table library(knitr) kable(compare) real Estimate SE Post.mean Post.sd psi 0.8 0.7653197 0.3262574 0.7637476 0.3244823 beta -1.5 -1.4129006 0.6239572 -1.4747848 0.6319201 p 0.6 0.6004304 0.0735178 0.6005410 0.0744655 alpha1 2.0 2.1395071 0.1494144 2.1470247 0.1515634 alpha2 1.0 0.9003900 0.1261927 0.9021164 0.1257829 alpha3 1.5 1.6801587 0.2513946 1.6858529 0.2468270 7.3 Bayesian estimates easily The JAGS code adds another layer of complexity to the analysis. Fortunately, since the year 2022, there is a new package in the neighborhood. The ubms package allows Bayesian estimates using the same easy and simple unmarked structure. The package has a formula-based interface compatible with unmarked, but the model is fit using MCMC with Stan instead of using maximum likelihood. ## ## Call: ## stan_occu(formula = ~elev + temp + elev:temp ~ elev, data = umf, ## chains = 3, cores = 3) ## ## Occupancy (logit-scale): ## Estimate SD 2.5% 97.5% n_eff Rhat ## (Intercept) 1.16 0.325 0.567 1.812 3548 1.000 ## elev -1.27 0.568 -2.447 -0.223 2970 0.999 ## ## Detection (logit-scale): ## Estimate SD 2.5% 97.5% n_eff Rhat ## (Intercept) 0.398 0.0742 0.257 0.555 3054 1 ## elev 2.117 0.1481 1.825 2.419 2670 1 ## temp 0.882 0.1272 0.633 1.134 2931 1 ## elev:temp 1.627 0.2514 1.129 2.147 3109 1 ## ## LOOIC: 1657.562 ## Runtime: 6.215 sec Advantages of ubms compared to unmarked: Obtain posterior distributions of parameters and derived parameters. Include random effects in parameter formulas (same syntax as lme4). Assess model fit using WAIC and LOO via the loo package. Disadvantages compared to unmarked: MCMC is slower than maximum likelihood. Not all model types are supported. Potential for convergence issues "],["r-session-information-and-packages-used.html", "Chapter8 R session information and packages used", " Chapter8 R session information and packages used sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 14393) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Spanish_Colombia.1252 LC_CTYPE=Spanish_Colombia.1252 ## [3] LC_MONETARY=Spanish_Colombia.1252 LC_NUMERIC=C ## [5] LC_TIME=Spanish_Colombia.1252 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggmcmc_1.5.1.1 ggplot2_3.3.6 tidyr_1.1.4 ## [4] dplyr_1.0.7 mcmcplots_0.4.3 coda_0.19-4 ## [7] jagsUI_1.5.2 spatstat_2.2-0 spatstat.linnet_2.3-0 ## [10] spatstat.core_2.3-0 spatstat.geom_2.2-2 rpart_4.1-15 ## [13] nlme_3.1-152 spatstat.data_2.1-0 raster_3.5-15 ## [16] sp_1.4-5 unmarked_1.1.1 Rcpp_1.0.8.3 ## [19] lattice_0.20-44 knitr_1.39 bookdown_0.24 ## ## loaded via a namespace (and not attached): ## [1] sass_0.4.0 sfsmisc_1.1-11 jsonlite_1.8.0 ## [4] splines_4.0.3 bslib_0.2.5.1 assertthat_0.2.1 ## [7] highr_0.9 yaml_2.3.5 pillar_1.7.0 ## [10] glue_1.6.2 digest_0.6.29 RColorBrewer_1.1-3 ## [13] polyclip_1.10-0 colorspace_2.0-3 htmltools_0.5.1.1 ## [16] Matrix_1.3-4 plyr_1.8.7 spatstat.sparse_2.0-0 ## [19] pkgconfig_2.0.3 purrr_0.3.4 scales_1.2.0 ## [22] rjags_4-13 tensor_1.5 terra_1.5-21 ## [25] spatstat.utils_2.2-0 tibble_3.1.7 mgcv_1.8-36 ## [28] generics_0.1.2 ellipsis_0.3.2 withr_2.5.0 ## [31] cli_3.2.0 magrittr_2.0.3 crayon_1.5.1 ## [34] deldir_1.0-2 evaluate_0.15 GGally_2.1.2 ## [37] fansi_1.0.3 MASS_7.3-54 tools_4.0.3 ## [40] lifecycle_1.0.1 stringr_1.4.0 munsell_0.5.0 ## [43] compiler_4.0.3 jquerylib_0.1.4 rlang_1.0.2 ## [46] grid_4.0.3 rstudioapi_0.13 goftest_1.2-2 ## [49] rmarkdown_2.14 gtable_0.3.0 codetools_0.2-18 ## [52] reshape_0.8.8 abind_1.4-5 DBI_1.1.2 ## [55] R6_2.5.1 denstrip_1.5.4 utf8_1.2.2 ## [58] stringi_1.7.6 parallel_4.0.3 vctrs_0.4.1 ## [61] png_0.1-7 tidyselect_1.1.1 xfun_0.31 "],["references.html", "References", " References Burnham, K. P., &amp; Anderson, D. R. (2004). Information and likelihood theory: A basis for model selection and inference. In K. P. Burnham &amp; D. R. Anderson (Eds.), Model selection and multimodel inference: A practical information-theoretic approach (pp. 4997). New York: Springer New York. Retrieved from http://link.springer.com/chapter/10.1007%2F978-0-387-22456-5_2 Fiske, I., &amp; Chandler, R. (2011). unmarked : An R Package for fitting hierarchical models of wildlife occurrence and abundance. Journal of Statistical Software, 43(10), 123. doi: 10.18637/jss.v043.i10 Guillera-Arroita, G. (2011). Impact of sampling with replacement in occupancy studies with spatial replication. Methods in Ecology and Evolution, 2(4), 401406. doi: 10.1111/j.2041-210X.2011.00089.x Guillera-Arroita, G., &amp; Lahoz-Monfort, J. J. (2012). Designing studies to detect differences in species occupancy: power analysis under imperfect detection. Methods in Ecology and Evolution, 3(5), 860869. doi: 10.1111/j.2041-210X.2012.00225.x Guillera-Arroita, G., Lahoz-Monfort, J. J., Elith, J., Gordon, A., Kujala, H., Lentini, P. E.,  Wintle, B. A. (2015). Is my species distribution model fit for purpose? Matching data and models to applications. Global Ecology and Biogeography, 24(3), 276292. doi: 10.1111/geb.12268 Guillera-Arroita, G., Ridout, M. S., &amp; Morgan, B. J. T. (2010). Design of occupancy studies with imperfect detection. Methods in Ecology and Evolution, 1(2), 131139. doi: 10.1111/j.2041-210X.2010.00017.x Guillera-Arroita, G., Ridout, MartinS., &amp; Morgan, ByronJ. T. (2014). Two-Stage Bayesian Study Design for Species Occupancy Estimation. Journal of Agricultural, Biological, and Environmental Statistics, 114. doi: 10.1007/s13253-014-0171-4 Kéry, M. (2008). Estimating abundance from bird counts: binomial mixture models uncover complex covariate relationships. The Auk, 125(2), 336345. doi: 10.1525/auk.2008.06185 Kéry, Marc, Guillera-Arroita, G., &amp; Lahoz-Monfort, J. J. (2013). Analysing and mapping species range dynamics using occupancy models. Journal of Biogeography, 40(8), 14631474. doi: 10.1111/jbi.12087 Kéry, M., &amp; Royle, J. A. (2008). Hierarchical Bayes estimation of species richness and occupancy in spatially replicated surveys. Journal of Applied Ecology, 45(2), 589598. doi: 10.1111/j.1365-2664.2007.01441.x Kéry, Marc, &amp; Schaub, M. (2012). Estimation of Occupancy and Species Distributions from Detection/Nondetection Data in Metapopulation Designs Using Site-Occupancy Models. In Bayesian population analysis using WinBUGS (pp. 413461). Elsevier. doi: 10.1016/B978-0-12-387020-9.00013-4 MacKenzie, Darryl I., Nichols, J. D., Hines, J. E., Knutson, M. G., &amp; Franklin, A. B. (2003). Estimating site occupancy, colonization, and local extinction when a species is detected imperfectly. Ecology, 84(8), 22002207. doi: 10.1890/02-3090 MacKenzie, Darryl I., Nichols, J. D., Lachman, G. B., Droege, S., Andrew Royle, J., &amp; Langtimm, C. A. (2002). Estimating site occupancy rates when detection probabilities are less than one. Ecology, 83(8), 22482255. doi: 10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2 MacKenzie, Darryl I., Nichols, J., Royle, J. A., Pollock, K., Bailey, L., &amp; Hines, J. (2006). Occupancy estimation and modeling: inferring patterns and dynamics of species occurrence (p. 324). Burlington, MA: Academic Press. MacKenzie, Darryl I., &amp; Royle, J. A. (2005). Designing occupancy studies: general advice and allocating survey effort. Journal of Applied Ecology, 42(6), 11051114. doi: 10.1111/j.1365-2664.2005.01098.x R Core Team. (2016). R: A language and environment for statistical computing. Vienna, Austria: R Foundation for Statistical Computing. Retrieved from http://www.r-project.org/ Royle, J. Andrew. (2006). Site occupancy models with heterogeneous detection probabilities. Biometrics, 62(1), 97102. doi: 10.1111/j.1541-0420.2005.00439.x Royle, J. Andrew, &amp; Kéry, M. (2007). A Bayesian state-space formulation of dynamic occupancy models. Ecology, 88(7), 18131823. doi: 10.1890/06-0669.1 Royle, J. Andrew, Nichols, J. D., K&amp;eacute, &amp; Ry, M. (2005). Modelling occurrence and abundance of species when detection is imperfect. Oikos, 110, 353359. doi: 10.1111/j.0030-1299.2005.13534.x "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
